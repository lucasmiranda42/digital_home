[{"content":"DeepOF es un paquete de Python para procesar datos de trackeo de animales, obtenidos con DeepLabCut o SLEAP. Las herramientas que tenemos disponibles para cuantificar lo que hacen los animales evolucionaron significativamente en la última década. Desde la observación de animales en la naturaleza, la etología se desplazó significativamente hacia pruebas más simples y controladas en el laboratorio, generalmente midiendo respuestas sencillas a ciertos estímulos.\nAvances recientes en visión por computadora y aprendizaje automático permitieron a los investigadores rastrear en detalle el movimiento de animales tanto en el laboratorio como en la naturaleza, sin la necesidad de etiquetas físicas. Típicamente, estos programas se basan en transfer learning (aprendizaje por transferencia) a partir de redes neuronales preentrenadas en grandes conjuntos de datos de imágenes, que primero extraen representaciones de los fotogramas de video. Al etiquetar relativamente pocos fotogramas con partes del cuerpo de interés (unos 200 suelen bastar), las redes pueden luego ajustarse para rastrear estas partes del cuerpo en todos los videos a disposición. Abajo podés ver el flujo de trabajo general del artículo original de DeepLabCut. Modelos más modernos pueden rastrear partes del cuerpo de interés incluso sin etiquetado previo, aunque siguen siendo menos precisas que estos métodos supervisados.\nDe esta forma, transformando el video crudo en series temporales de partes del cuerpo rastreadas, estos programas (incluyendo los mencionados DeepLabCut y SLEAP) allanaron el camino para herramientas de análisis que pueden etiquetar y caracterizar automáticamente el comportamiento de muchas maneras innovadoras.\nDeepOF es nuestra humilde contribución a este esfuerzo. El programa ofrece tanto funciones de anotación tanto supervisada como no supervisada, que permiten a los investigadores probar hipótesis sobre condiciones experimentales como el estrés, mutaciones genéticas y sexo, de una manera flexible.\nEn primer lugar, la anotación supervisada incluido usa una serie de reglas y modelos de aprendizaje automático preentrenados para detectar cuándo los animales que se están rastreando muestran alguno de una serie de patrones de comportamiento predefinidos.\nDe esta manera, podemos etiquetar tanto comportamientos individuales como sociales con solo unas pocas líneas de código! Veamos un ejemplo básico:\nimport deepof.data my_deepof_project_raw = deepof.data.Project( project_path=os.path.join(\u0026#34;tutorial_files\u0026#34;), video_path=os.path.join(\u0026#34;tutorial_files/Videos/\u0026#34;), table_path=os.path.join(\u0026#34;tutorial_files/Tables/\u0026#34;), project_name=\u0026#34;deepof_example_project\u0026#34;, ) supervised_annotation = my_deepof_project.supervised_annotation() Así de fácil, anotamos todos nuestros videos con un conjunto de modelos preentrenados que pueden detectar comportamientos tales como encogerse, trepar, y distintas interacciones sociales.\nAdemás, como mencionamos arriba, DeepOF también viene con un flujo de trabajo no supervisado, que modelos modelos de agrupamiento profundo para descubrir patrones de comportamiento sin definición previa, que también se puede ejecutar con unos pocos comandos:\n# Continuando desde arriba, creamos un conjunto de coordenadas para agrupar, # removiendo variación posicional y rotacional que no nos interesa coords = my_deepof_project.get_coords(center=\u0026#34;Center\u0026#34;, align=\u0026#34;Spine_1\u0026#34;) # Luego preprocesamos estas coordenadas para hacerlas compatibles con el clustering preprocessed_coords, global_scaler = coords.preprocess() # Finalmente, entrenamos un modelo de clustering con estas coordenadas preprocesadas trained_model = my_deepof_project.deep_unsupervised_embedding( preprocessed_object=preprocessed_coords ) Por último, DeepOF incluye un pipeline de interpretabilidad para explorar qué son estos clusters obtenidos, basándonos tanto en Shapley Additive Explanations (SHAP) como en mapeos directos de clusters a fragmentos de video. Además, independientemente del tipo de análisis que elijas, DeepOF te ofrece un extenso conjunto de herramientas de análisis y visualización post-hoc. A continuación podés ver los resultados de SHAP para un cluster enriquecido en animales expuestos a estrés crónico, junto a fragmentos de video correspondientes.\n¡Eso es todo por ahora! En resumen, DeepOF es una herramienta versátil que puede ayudarte a extraer información significativa de tus datos de comportamiento animal. ¡Esperamos que la encuentres tan útil como nosotros!\n¿Y ahora qué? DeepOF está disponible en GitHub y PyPI. Acá podés encontrar documentación detallada, incluyendo instalación en distintos sistemas operativos y tutoriales. Si te interesa entrar en detalle, podés leer nuestras dos publicaciones. La primera es sobre el software en sí, mientras que la segunda describe cómo usamos DeepOF para caracterizar un modelo de ratón de estrés crónico.\n","permalink":"//localhost:1313/es/software/deepof/deepof/","summary":"DeepOF es una herramienta de postprocesado para series temporales de datos de comportamiento animal, obtenidas a través de DeepLabCut o SLEAP.","title":"DeepOF"},{"content":"Impresiones generales Esta vez escribo desde Viena, Austria, ciudad que visité con motivo de la Conferencia Internacional sobre Aprendizaje Automático (ICML). Organicé mi agenda mucho mejor que la última vez, y obtuve mucha información sobre los nuevos avances en varias áreas que me interesan, como la representación de series temporales, la informática médica y la biología computacional de proteínas. Abajo mi humilde selección de artículos favoritos. Espero que encuentres algo interesante.\nAprendizaje por contraste para la predicción de resultados clínicos con fuentes de datos parciales Empezamos con una contribución significativa al campo de la informática médica. A medida que las historias clínicas electrónicas(EHR, por sus siglas en inglés) se hacen más y más comunes en todo el mundo, vemos que los nuevos métodos para procesarlas, representarlas y predecir a partir de ellas cobran cada vez más importancia. En este caso, los autores presentan CLOPPS (Contrastive Learning for clinical Outcome Prediction with Partial data Sources), cuyo objetivo es capturar información de distintas fuentes de datos de los mismos pacientes y alinearlas durante el entrenamiento mediante aprendizaje por contraste. Es importante destacar que lo hacen de manera que no todas las modalidades son necesarias en el momento de la inferencia, lo que constituye una limitación común en muchos modelos en este campo.\nLa figura de arriba representa el flujo de trabajo de preentrenamiento que los autores usan en CLOPPS: dadas dos observaciones longitudinales, el descodificador de la izquierda produce representaciones para cada modalidad, que luego se alinean contrastivamente en el espacio latente. La función de coste total es la suma de dos términos InfoNCE, que siguen estrategias separadas de muestreo de pares positivos/negativos, y un término de predicción a futuro (forecasting). El primero, \\(L_M\\), busca imponer coincidencia temporal entre modalidades. Acá, la asunción es que las distintas fuentes representan de forma colectiva y complementaria el estado de salud en ese momento, por lo que muestras tomadas al mismo tiempo en diversas fuentes son las únicas consideradas como pares positivos. En segundo lugar, el modelo incorpora un término de similitud local bastante original (\\(L_L\\)), basado en un estimador de Kaplan-Meier (KM) para el fenómeno que se esté intentando predecir. La idea es simple: si el paciente está sano, las series temporales no cambian tanto en un periodo de tiempo corto, y la amplitud del vecindario local del que muestrear pares positivos puede ser mayor. Si el paciente está enfermo, la curva de KM es más pronunciada y el vecindario del que tomar muestras de pares positivos es más chico. Mientras que \\(L_M\\) se encarga de alinear estrictamente las fuentes de datos a lo largo del tiempo, \\(L_L\\) se centra en las regiones de cambio rápido, que se corresponden con peores resultados según lo predicho por el estimador KM. Como idea me suena bárbara, y los estudios de ablación incluidos en el artículo muestran que es relevante. Por último, el tercer término, \\(L_F\\), es una pérdida de forecasting entrenada por modalidad de forma independiente.\nPara una revisión de la función de coste InfoNCE estándar, ¡pasate por este post!\nEn cuanto a los experimentos, los autores muestran rendimiento SOTA en una serie de escenarios, motivados por un problema del mundo real en el que los datos proceden tanto de un proveedor de diálisis como de un sistema de datos nacional estadounidense -el United States Renal Data System (USRDS)-. En este caso, como los datos del flujo nacional no siempre están disponibles, es crucial desarrollar un modelo que pueda hacer predicciones cuando falten algunos datos.\nTimesFM: un modelo fundacional decoder-only para forecasting de series temporales Este es un artículo que, como muchos otros procedentes de Google, estuvo por todo Internet cuando salió. Tenía muchas ganas de ver el póster, y me alegro de haber podido pasarme y charlar con los autores. Como indica el título, TimesFM es un modelo basado únicamente en decodificadores para el forecasting de series temporales univariadas, entrenado tanto en tendencias de Google como en estadísticas de acceso a wikimedia.\nLos datos están tokenizados a lo largo del tiempo, y la arquitectura se corresponde con un transformer sólo decodificador estándar, en el que los \u0026rsquo;tokens\u0026rsquo; pasan a través de un bloque residual en lugar de obtenerse de una tabla de búsqueda (como en los modelos de lenguaje tradicionales, por ejemplo), ya que los datos son continuos. El modelo se entrena para minimizar la el error cuadrático medio (MSE, por sus siglas en inglés) entre cada token y otro, obtenido en un horizonte \\(h\\) en el futuro.\nLa figura anterior ilustra la arquitectura del modelo TimesFM durante el entrenamiento, en el que una serie temporal de una longitud específica se descompone en una serie de parches. Como ya se mencionó, cada parche es procesado por un bloque residual que lo mapea a la dimensión necesaria para pasar por las capas del transformer. El modelo usa codificaciones posicionales sinusoidales (bien tradicionales, similares a las que se usan en el paper original presentando el transformer como arquitectura). La longitud de los parches y el horizonte \\(h\\) varían durante el entrenamiento, para evitar que el modelo se ajuste en exceso a una única configuración rígida.\nEl paper incluye una serie de experimentos que exploran diferentes configuraciones y esquemas de parcheo en diferentes benchmarks, alcanzando en muchos de ellos rendimiento SOTA en tareas de zero-shot. Aunque se trata sin duda de un artículo a tener en cuenta, una de sus principales limitaciones es que se centra únicamente en series temporales univariandas. A pesar de que el entrenamiento de modelos de representación en series temporales multivariadas es un problema mucho más difícil, hay varios trabajos recientes que ya estudian esta cuestión. Por ejemplo, iTransformer invierte la estrategia de codificación al tokenizar cada variable de forma independiente en toda la dimensión temporal, con un mecanismo de atención que se centra en las interacciones entre variables. Otro esfuerzo interesante, que alcanza rendimiento SOTA en muchas pruebas comparativas y aprovecha datos de múltiples fuentes, es UniTS. Este modelo tiene mecanismos de atención separados que funcionan tanto a entre variables como a través del tiempo, e incluye diferentes conjuntos de tokens para especificar una de varias tareas, incluyendo forecasting, imputación y detección de anomalías.\n2Bits de proteína: modelos de lenguaje proteicos eficientes a escala de 2 bits Por último, cambiamos un poco de tema y pasamos a los modelos de lenguaje de proteínas. 2Bits of protein es un artículo que se presentó durante los talleres del último día de la conferencia, que se basa en la idea reciente de entrenar modelos de lenguaje con parámetros ternarios, que pueden establecerse en cero, uno o menos uno. Se trata de un tema realmente relevante en el momento de escribir, habiéndose demostrado ampliamente que este tipo de modelos conservan la mayor parte de la precisión de sus homólogos de precisión completa, al tiempo que son mucho más eficientes en términos de memoria y costo computacional. Esto tiene implicaciones enormes para pequeñas y medianas empresas, así como para laboratorios de investigación que no tienen acceso a los mismos recursos computacionales que las grandes empresas del sector. Además, la capacidad de entrenar y ejecutar modelos localmente promete ventajas en términos de privacidad y seguridad de los datos, lo que es importante en cualquier aplicación relacionada con la salud (entre muchas otras, desde ya).\nEn este trabajo, los autores investigan el entrenamiento de un pLM sólo codificador utilizando una arquitectura ternaria, y lo comparan con ESM2 (con precisión estándar) en varias tareas de ProteinGym. Aunque el modelo ternario no es tan bueno como el de precisión estándar, sigue siendo competitivo en muchas tareas y es mucho más eficiente. Los autores también afirman que, basándose en el trabajo fundacional en este campo que menciono más arriba, cabe esperar que las variantes ternarias superen a ESM-2 una vez que se aumente el tamaño del modelo. ¡Esto está por verse!\nAcá un fragmento de los resultados (con leyendas autoexplicativas):\nEn definitiva, creo que el impacto de estos enfoques puede ser enorme tanto para los pequeños como para los grandes actores. Por un lado, permite a gente sin hardware SOTA entrenar y utilizar mejores modelos, pero también permite a las grandes empresas entrenar modelos mucho más grandes de lo que podrían hacerlo de otro modo. Veremos si estas prácticas se generalizan en los próximos años.\n","permalink":"//localhost:1313/es/blog/icml24/icml24/","summary":"Mis impresiones, pensamientos y artículos favoritos sobre la edición 2024 de ICML, a la que asistí en persona en Viena.","title":"International Conference on Machine Learning 2024"},{"content":"Impresiones Generales En diciembre pasado, tuve el placer de asistir a la edición 2023 de la conferencia Neural Information Processing Systems (NeurIPS) en Nueva Orleans. Era la primera vez que asistía a un evento tan grande, y debo admitir que me sentí un poco abrumado por la cantidad de personas y la inmensa cantidad de información disponible. Sin embargo, obtuve mucha información valiosa de las varias charlas interesantes y sesiones de póster a las que logré asistir, y me gustaría compartir algunos de mis fragmentos favoritos con quien esté interesado!. Abajo un resumen de los tres artículos que encontré más interesantes para mi investigación actual, así como un bonus track sobre un proyecto increíble que me retrotrajo a mis días de doctorado.\nContrastando todo (COMET) El primer artículo en la lista presenta COMET, un marco de aprendizaje por contraste para aprender representaciones de series temporales médicas de manera auto-supervisada. La principal contribución que los autores presentan es un esquema de entrenamiento jerárquico para codificadores de series temporales, con una función de coste que consta de cuatro niveles de contraste, con el fin de explotar y aprender de diferentes niveles de consistencia de datos que de otro modo podrían perderse. Para todos los niveles, utilizan variantes de función de coste InfoNCE (Information Noise Contrastive Estimation, en inglés), donde los pares positivos y negativos se obtienen enmascarando observaciones al azar en el input a los modelos.\nComo resumen, empecemos por describir la función InfoNCE más típica. Dado un conjunto de muestras \\(x_i\\) y un conjunto diferente \\(x_j\\), la InfoNCE se define como:\n$$ \\mathcal{L}_{\\text{InfoNCE}} = -\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{\\exp(\\text{sim}(x_i, x_i^+))}{\\sum_{j=1}^{K} \\exp(\\text{sim}(x_i, x_j^-))} $$donde \\(x_i^+\\) es una muestra positiva, \\(x_j^-\\) una muestra negativa, y \\(\\text{sim}\\) una función de similitud (típicamente el producto escalar entre las representaciones, pero podría ser cualquier otra cosa). La idea es maximizar la similitud entre las representaciones de pares positivos, mientras se minimiza para pares negativos (¡noten el signo \\(-\\)!). Pero, ¿cómo definimos pares positivos y negativos? Bueno, aquí es donde COMET brilla\u0026hellip;\nLos cuatro niveles que mencioné arriba se definen de la siguiente manera:\nNivel de Observación: Primero, las observaciones aumentadas del mismo punto en el tiempo se tratan como pares positivos \\((x_{i,t}, \\tilde{x}_{i,t})\\), mientras que las observaciones reales y aumentadas de diferentes puntos en el tiempo se tratan como negativas \\((x_{i,t}, x_{i,-t})\\) y \\((x_{i,t}, \\tilde{x}_{i,-t})\\), donde \\(x\\) es una muestra dada, \\(\\tilde{x}\\) una muestra aumentada, \\(i\\) el índice de muestra y \\(t\\) el índice temporal.\nNivel de Muestra: En segundo lugar, las observaciones aumentadas de la misma muestra se tratan como pares positivos \\((x_{i}, \\tilde{x}_{i})\\), mientras que las observaciones reales y aumentadas de diferentes muestras se tratan como negativas \\((x_{i}, x_{j})\\) y \\((x_{i}, \\tilde{x}_{j})\\).\nNivel de Ensayo: Como las series temporales pueden ser arbitrariamente largas, COMET contempla subdividir las muestras en el tiempo en pedazos (llamados trials en el paper original). En este término de la función de coste, aplicamos la misma función mencionada arriba, pero a una representación agregada de todo el trial en lugar de las representaciones de observaciones individuales. De los cuatro niveles, es el único que surge como un artefacto de las limitaciones del hardware, en lugar de las verdaderas consistencias en los datos. No está claro si esto sería necesario si el hardware no es un límite.\nNivel de Paciente: por último, pero no menos importante, repetimos el paso 3, pero ahora con los trials agrupados en función de si pertenecen al mismo paciente o no. Las series temporales diferentes muestreadas de los mismos individuos se consideran pares positivos, y como negativos en caso contrario.\nAl entrenar el codificador con estos cuatro niveles de pérdida por contraste, los autores buscan aprender representaciones que sean invariantes a los diferentes niveles de consistencia de datos.\nEl flujo de trabajo principal se ve así (chequeá el artículo completo para más detalles):\nLos experimentos en el paper se centran en datos de EEG (electroencefalograma) muestreados regularmente con pocos o ningún valor faltante. Sin embargo, el método parece ser un excelente punto de partida para el aprendizaje a partir de datos muestreados irregularmente (como las series temporales de UCI) también. A fin de cuentas, superaron varias líneas base de auto-supervisión de series temporales en la detección de infarto de miocardio y enfermedad de Parkinson.\nSeries Temporales como Imágenes: Transformer de Visión para Series Temporales Muestreadas Irregularmente Ahora pasamos a un artículo que llamó mi atención debido al pensamiento lateral en juego. Series Temporales como Imágenes presenta una forma peculiar de procesar series temporales muestreadas irregularmente para el aprendizaje supervisado, basada en la representación de los valores recopilados como imágenes y su procesamiento utilizando un transformer de visión swin preentrenado. Los autores realizan varios experimentos poco ortodoxos sobre cómo diferentes estilos de representación afectan el rendimiento, como marcadores, interpolación, orden de las variables, y colores. Además, incluyen varios experimentos en datos de unidades de cuidados intensivos, e incluyen comparaciones directas con muchas líneas base, incluido SeFT del laboratorio Borgwardt (donde trabajo). Alcanzan un rendimiento de SOTA en varias tareas, incluida la predicción de septicemia y mortalidad en datos de los desafíos PhysioNet 2019 y 2012, respectivamente. Entrenan los modelos con una simple función de coste para clasificación binaria (entropía cruzada binaria), mientras aumentan la clase minoritaria. Curiosamente, también incluyeron información estática (edad, altura, peso, sexo, demografía) como un párrafo representado con un modelo de lenguaje solo encoder\u0026hellip; Las representaciones de series temporales y texto se concatenaron antes de la clasificación. Verdaderamente poco ortodoxo, ¡pero parece funcionar!\nEl flujo de trabajo principal se ve así (de nuevo, chequeá el artículo para más detalles):\nEn general, este artículo demuestra claramente las capacidades de generalización de los grandes modelos de visión, pero queda por ver si sus ideas se pueden extender para hacer modelos de series temporales generalizables.\nUn Marco Iterativo de Auto-Aprendizaje para la Generalización en el Dominio Médico Finalmente, el tercer trabajo en este resumen presenta un enfoque para mitigar el cambio de distribución en datos de registros médicos electrónicos (EHR), denominado SLDG (Generalización de Dominio de Auto-Aprendizaje, por sus siglas en inglés). En resumen, el enfoque comienza agrupando las características semánticamente en diferentes clases (como estáticas, síntomas, tratamientos e historia médica). Cada subconjunto de características se representa con un codificador entrenado en un espacio latente individual, y se recupera una serie de dominios latentes para cada modalidad utilizando clustering jerárquico, con el número de clústeres seleccionado automáticamente en función del silhouette score. Esto facilita la detección de clústeres realmente específicos como la intersección de grupos no tan raros de características específicas (como un clúster de pacientes mayores de edad con antecedentes de tabaquismo y diabetes tipo 2, que se puede descomponer en mayor, masculino, fumador y diabetes tipo 2). Por último, se entrenan clasificadores individuales para una variable objetivo dada para cada una de estas clases de características, con clústeres recalculados cada 20 épocas.\nSus experimentos se centran en la predicción de readmisión a 15 días y mortalidad tanto en MIMIC-IV como en eICU, con divisiones de datos que maximizan las brechas temporales y espaciales entre las muestras, siendo la última basada en la ubicación geográfica de los hospitales. Superaron varias líneas base de generalización de dominio en todas las tareas y métricas, lo cual suena prometedor. Curiosamente, no proporcionan métricas de generalización entre eICU y MIMIC-IV; solo dentro de cada conjunto de datos individualmente.\nEn general, parece un enfoque inteligente para agrupar eficientemente representaciones basadas en el conocimiento previo sobre las distintas variables en juego, lo cual puede tener un impacto positivo en tareas de adaptación de dominio.\nBonus track: AmadeusGPT: una interfaz de lenguaje natural para el análisis interactivo del comportamiento animal Durante mi doctorado, trabajé mucho con datos de seguimiento de movimientos provenientes de experimentos con animales. El estado absoluto del arte, tanto en términos de rendimiento como de soporte al usuario, para el seguimiento de movimientos en biología, es DeepLabCut. Sin embargo, el software principal no es el más amigable para el usuario y puede ser bastante engorroso para los biólogos de laboratorio que lo usan habitualmente. Acá es donde entra en juego (¿o en canción?) AmadeusGPT. Aprovechando varios hitos del laboratorio Mathis, como DLC super animal (un modelo que permite el seguimiento de animales sin entrenamiento previo), segmentación de objetos usando SAM y llamadas API a ChatGPT, los autores (¡también el equipo de DeepLabCut!) presentan una interfaz de lenguaje natural para el análisis interactivo del comportamiento animal, donde el usuario puede hacer preguntas sobre los datos en inglés, y el sistema devuelve la información relevante.\nAl momento de escribir esto, el sistema sólo está disponible previa solicitud (lo cual es comprensible, dado el costo de las llamadas API de ChatGPT a gran escala), pero parece un gran paso adelante para hacer que la tecnología de vanguardia sea más accesible al público en general. ¡Veremos cómo evoluciona este proyecto!\n","permalink":"//localhost:1313/es/blog/neurips23/neurips23/","summary":"Mis impresiones, pensamientos y artículos favoritos sobre la edición 2023 de NeurIPS, a la que asistí en persona en Nueva Orleans.","title":"Neural Information Processing Systems 2023"},{"content":"¿Alguna vez te preguntaste cómo sabemos lo que sabemos sobre el cerebro? ¿Cómo los científicos y médicos intentan (y logran, y fallan) aplicar este conocimiento para mejorar la vida de quienes sufren?\nEl grupo PsyComm de IMPRS-TP es un grupo de estudiantes de doctorado que creen en la importancia de comunicar la ciencia al público en general y, especialmente, a chicos y adolescentes, en un esfuerzo por fomentar el pensamiento científico desde una edad temprana. Nuestro objetivo es educar al público general desde joven, sobre la salud mental y las enfermedades mentales. De esta manera, esperamos aumentar la conciencia y reducir el estigma asociado con ellas.\nCon esto en mente, diseñamos un pequño libro para ofrecer una visión general de los fundamentos de la salud mental y de cómo se investiga. En términos sencillos que pretenden ser accesibles para todos, narramos los conceptos básicos de la anatomía y función del cerebro, y lo que sabemos sobre cómo pueden ocurrir las enfermedades mentales. Además, profundizamos en la genética y en la influencia del entorno en nuestro comportamiento, transmitiendo que, contrariamente a la falsa dicotomía popular, el comportamiento tanto se nace como se hace.\nEn resumen, los capítulos de este libro te van a ayudar (a vos y/o a tus hijes) a comprender los principios científicos que subyacen a la función mental, la enfermedad y el proceso de investigación que se sigue hoy en día para estudiarlas.\nSi bien lamentablemente el folleto oficial sólo está disponible en inglés y en alemán, la versión no editada en castellano se puede descargar acá. ¡Esperamos te resulte útil!\nSi tienes alguna pregunta o comentario, no dudes en ponerte en contacto con nosotros en imprs-tp-scicomm@psych.mpg.de.\nPersonalmente, me gustaría tomar un momento para agradecer a todos y cada uno de los miembros del grupo. Fue un placer trabajar con todos ustedes, y estoy orgulloso de lo que logramos juntos. Al momento de escribir esto, muchos de nosotros ya terminamos el doctorado y avanzamos en nuestras carreras, ¡pero estoy deseando ver qué depara el futuro para los nuevos miembros!\nMiembros que participaron en la escritura y edición (de arriba a la izquierda a abajo a la derecha): Lea Brix, Anthi Krontira, Marius Stephan, Elena Brivio, Sowmya Narayan, Adyasha Kunthia, Lucas Miranda, Srivaishnavi Loganathan, Anna Fröhlich, Anna Zych, Muriel Frisch, Cassandra Deichsel, Linda Dieckmann, Mira Erhart, Nicolas Rost y Julia Fietz. Ane Ayo Martin no está en la foto.\n","permalink":"//localhost:1313/es/blog/psycomm/psycomm_booklet/","summary":"Como parte del grupo de comunicación científica del Instituto Max Planck de Psiquiatría, escribimos y publicamos un folleto sobre salud mental e investigación en salud mental para niños. ¡Ven y échale un vistazo!","title":"Salud mental, explicada para todos"},{"content":"","permalink":"//localhost:1313/es/pubs/conformal_amr/","summary":"","title":"Detecting antimicrobial resistance through MALDI-TOF mass spectrometry with statistical guarantees using conformal prediction"},{"content":"","permalink":"//localhost:1313/es/pubs/early_life_stress_metabolism/","summary":"","title":"Sex-specific fear acquisition following early life stress is linked to amygdala and hippocampal purine and glutamate metabolism"},{"content":"","permalink":"//localhost:1313/es/pubs/phd_thesis/","summary":"","title":"Deep clustering of animal motion tracking data: software development and applications to psychiatric preclinical research"},{"content":" Este es mi espacio digital. Acá vas a encontrar contenido sobre mi vida profesional, incluyendo publicaciones científicas, proyectos, software, y (de vez en cuando) entradas de blog de interés general.\nMi nombre es Lucas Miranda. Nací y crecí en Buenos Aires, Argentina, donde estudié biología molecular y bioinformática en la Universidad de Buenos Aires. Recientemente completé mi doctorado en la Universidad Técnica de Munich, dirigido por Bertram Müller-Myhsok en el Instituto Max Planck de Psiquiatría. Si te interesa, podés leer mi tesis (en inglés) acá.\nDesde junio de 2023, trabajo como investigador postdoctoral en el Instituto Max Planck de Bioquímica en Munich, Alemania, como parte del grupo de investigación de Machine Learning y Biología de Sistemas. Mi investigación actual se centra en el aprendizaje de representaciones de datos biológicos y médicos, con un interés particular en proteómica clínica y en series temporales relevantes para medicina, tales como historiales médicos electrónicos y datos de unidades de terapia intensiva.\nVivimos en tiempos emocionantes, donde los modelos de aprendizaje automático mejoran día a día en muchos dominios. Mi objetivo es aportar mi grano de arena al desarrollo de estas tecnologías en mmedicina, lo que en última instancia nos puede beneficiar a todos. Gracias por leer, ¡y espero que encuentres algo útil!\n","permalink":"//localhost:1313/es/about/","summary":"\u003chr\u003e\n\u003cp\u003eEste es mi espacio digital. Acá vas a encontrar contenido sobre mi vida profesional, incluyendo publicaciones científicas, proyectos, software, y (de vez en cuando) entradas de blog de interés general.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eMi nombre es Lucas Miranda. Nací y crecí en \u003ca href=\"https://www.youtube.com/watch?v=Pb9Hv9lw5Tw\"\u003eBuenos Aires, Argentina\u003c/a\u003e, donde estudié biología molecular y bioinformática en la \u003ca href=\"https://www.uba.ar/\"\u003eUniversidad de Buenos Aires\u003c/a\u003e. Recientemente completé mi doctorado en la \u003ca href=\"https://www.tum.de/en/\"\u003eUniversidad Técnica de Munich\u003c/a\u003e, dirigido por Bertram Müller-Myhsok en el \u003ca href=\"https://www.psych.mpg.de/1495975/mueller_myhsok\"\u003eInstituto Max Planck de Psiquiatría\u003c/a\u003e. Si te interesa, podés leer mi tesis (en inglés) \u003ca href=\"https://mediatum.ub.tum.de/?id=1713444\"\u003eacá\u003c/a\u003e.\u003c/p\u003e","title":"Sobre mí"},{"content":"","permalink":"//localhost:1313/es/pubs/early_life_stress_hippocampus/","summary":"","title":"Early life adversity shapes social subordination and cell type–specific transcriptomic patterning in the ventral hippocampus"},{"content":"","permalink":"//localhost:1313/es/pubs/multimodal_amr/","summary":"","title":"Multimodal learning in clinical proteomics: enhancing antimicrobial resistance prediction models with chemical information"},{"content":"","permalink":"//localhost:1313/es/pubs/social_beh_ns_review/","summary":"","title":"Advancing social behavioral neuroscience by integrating ethology and comparative psychology methods through machine learning"},{"content":"","permalink":"//localhost:1313/es/pubs/deepof_ncomms/","summary":"","title":"Automatically annotated motion tracking identifies a distinct social behavioral profile following chronic social defeat stress"},{"content":"","permalink":"//localhost:1313/es/pubs/deepof_joss/","summary":"","title":"DeepOF: A Python package for supervised and unsupervised pattern recognition in mice motion tracking data"},{"content":"","permalink":"//localhost:1313/es/pubs/mirnas_uba/","summary":"","title":"miRNAs associated with endoplasmic reticulum stress and unfolded protein response during decidualization"},{"content":"","permalink":"//localhost:1313/es/pubs/stress_commentary/","summary":"","title":"Increasing resolution in stress neurobiology: from single cells to complex group behaviors"},{"content":"","permalink":"//localhost:1313/es/pubs/fmri_review/","summary":"","title":"Systematic review of functional MRI applications for psychiatric disease subtyping"},{"content":"","permalink":"//localhost:1313/es/pubs/mips_uba/","summary":"","title":"Comprehensive identification of pathogenic gene variants in patients with neuroendocrine disorders"},{"content":"","permalink":"//localhost:1313/es/pubs/nfkb_uba/","summary":"","title":"The transcription factor NF-kB mediates thyrotropin-stimulated expression of thyroid differentiation markers"}]