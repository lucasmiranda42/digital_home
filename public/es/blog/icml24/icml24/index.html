
<!DOCTYPE html>
<html lang="es" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>International Conference on Machine Learning 2024 | Lucas Miranda</title>
<meta name="keywords" content="Conferencias, Aprendizaje Autom√°tico, Aprendizaje Profundo, Viajes, ICML, Austria, Viena">
<meta name="description" content="Mis impresiones, pensamientos y art√≠culos favoritos sobre la edici√≥n 2024 de ICML, a la que asist√≠ en persona en Viena.">
<meta name="author" content="Lucas Miranda">
<link rel="canonical" href="//localhost:1313/es/blog/icml24/icml24/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.1f0c81ce7797be919c6536baf557152f60cccb49e7a37ce74f7fd3fd705259f6.css" integrity="sha256-HwyBzneXvpGcZTa69VcVL2DMy0nno3znT3/T/XBSWfY=" rel="preload stylesheet" as="style">
<link rel="icon" href="//localhost:1313/assets/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="//localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="//localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="//localhost:1313/en/blog/icml24/icml24/">
<link rel="alternate" hreflang="es" href="//localhost:1313/es/blog/icml24/icml24/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="International Conference on Machine Learning 2024" />
<meta property="og:description" content="Mis impresiones, pensamientos y art√≠culos favoritos sobre la edici√≥n 2024 de ICML, a la que asist√≠ en persona en Viena." />
<meta property="og:type" content="article" />
<meta property="og:url" content="//localhost:1313/es/blog/icml24/icml24/" />
<meta property="og:image" content="//localhost:1313/ICML_logo.png" /><meta property="article:section" content="blog" />


<meta property="og:see_also" content="//localhost:1313/es/blog/neurips23/neurips23/" />

<meta property="og:see_also" content="//localhost:1313/es/blog/neurips23/neurips23/" />





<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="//localhost:1313/ICML_logo.png" />
<meta name="twitter:title" content="International Conference on Machine Learning 2024"/>
<meta name="twitter:description" content="Mis impresiones, pensamientos y art√≠culos favoritos sobre la edici√≥n 2024 de ICML, a la que asist√≠ en persona en Viena."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blog",
      "item": "//localhost:1313/es/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "International Conference on Machine Learning 2024",
      "item": "//localhost:1313/es/blog/icml24/icml24/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "International Conference on Machine Learning 2024",
  "name": "International Conference on Machine Learning 2024",
  "description": "Mis impresiones, pensamientos y art√≠culos favoritos sobre la edici√≥n 2024 de ICML, a la que asist√≠ en persona en Viena.",
  "keywords": [
    "Conferencias", "Aprendizaje Autom√°tico", "Aprendizaje Profundo", "Viajes", "ICML", "Austria", "Viena"
  ],
  "articleBody": "Impresiones generales Esta vez escribo desde Viena, Austria, ciudad que visit√© con motivo de la Conferencia Internacional sobre Aprendizaje Autom√°tico (ICML). Organic√© mi agenda mucho mejor que la √∫ltima vez, y obtuve mucha informaci√≥n sobre los nuevos avances en varias √°reas que me interesan, como la representaci√≥n de series temporales, la inform√°tica m√©dica y la biolog√≠a computacional de prote√≠nas. Abajo mi humilde selecci√≥n de art√≠culos favoritos. Espero que encuentres algo interesante.\nAprendizaje por contraste para la predicci√≥n de resultados cl√≠nicos con fuentes de datos parciales Empezamos con una contribuci√≥n significativa al campo de la inform√°tica m√©dica. A medida que las historias cl√≠nicas electr√≥nicas(EHR, por sus siglas en ingl√©s) se hacen m√°s y m√°s comunes en todo el mundo, vemos que los nuevos m√©todos para procesarlas, representarlas y predecir a partir de ellas cobran cada vez m√°s importancia. En este caso, los autores presentan CLOPPS (Contrastive Learning for clinical Outcome Prediction with Partial data Sources), cuyo objetivo es capturar informaci√≥n de distintas fuentes de datos de los mismos pacientes y alinearlas durante el entrenamiento mediante aprendizaje por contraste. Es importante destacar que lo hacen de manera que no todas las modalidades son necesarias en el momento de la inferencia, lo que constituye una limitaci√≥n com√∫n en muchos modelos en este campo.\nLa figura de arriba representa el flujo de trabajo de preentrenamiento que los autores usan en CLOPPS: dadas dos observaciones longitudinales, el descodificador de la izquierda produce representaciones para cada modalidad, que luego se alinean contrastivamente en el espacio latente. La funci√≥n de coste total es la suma de dos t√©rminos InfoNCE, que siguen estrategias separadas de muestreo de pares positivos/negativos, y un t√©rmino de predicci√≥n a futuro (forecasting). El primero, \\(L_M\\), busca imponer coincidencia temporal entre modalidades. Ac√°, la asunci√≥n es que las distintas fuentes representan de forma colectiva y complementaria el estado de salud en ese momento, por lo que muestras tomadas al mismo tiempo en diversas fuentes son las √∫nicas consideradas como pares positivos. En segundo lugar, el modelo incorpora un t√©rmino de similitud local bastante original (\\(L_L\\)), basado en un estimador de Kaplan-Meier (KM) para el fen√≥meno que se est√© intentando predecir. La idea es simple: si el paciente est√° sano, las series temporales no cambian tanto en un periodo de tiempo corto, y la amplitud del vecindario local del que muestrear pares positivos puede ser mayor. Si el paciente est√° enfermo, la curva de KM es m√°s pronunciada y el vecindario del que tomar muestras de pares positivos es m√°s chico. Mientras que \\(L_M\\) se encarga de alinear estrictamente las fuentes de datos a lo largo del tiempo, \\(L_L\\) se centra en las regiones de cambio r√°pido, que se corresponden con peores resultados seg√∫n lo predicho por el estimador KM. Como idea me suena b√°rbara, y los estudios de ablaci√≥n incluidos en el art√≠culo muestran que es relevante. Por √∫ltimo, el tercer t√©rmino, \\(L_F\\), es una p√©rdida de forecasting entrenada por modalidad de forma independiente.\nPara una revisi√≥n de la funci√≥n de coste InfoNCE est√°ndar, ¬°pasate por este post!\nEn cuanto a los experimentos, los autores muestran rendimiento SOTA en una serie de escenarios, motivados por un problema del mundo real en el que los datos proceden tanto de un proveedor de di√°lisis como de un sistema de datos nacional estadounidense -el United States Renal Data System (USRDS)-. En este caso, como los datos del flujo nacional no siempre est√°n disponibles, es crucial desarrollar un modelo que pueda hacer predicciones cuando falten algunos datos.\nTimesFM: un modelo fundacional decoder-only para forecasting de series temporales Este es un art√≠culo que, como muchos otros procedentes de Google, estuvo por todo Internet cuando sali√≥. Ten√≠a muchas ganas de ver el p√≥ster, y me alegro de haber podido pasarme y charlar con los autores. Como indica el t√≠tulo, TimesFM es un modelo basado √∫nicamente en decodificadores para el forecasting de series temporales univariadas, entrenado tanto en tendencias de Google como en estad√≠sticas de acceso a wikimedia.\nLos datos est√°n tokenizados a lo largo del tiempo, y la arquitectura se corresponde con un transformer s√≥lo decodificador est√°ndar, en el que los ‚Äôtokens‚Äô pasan a trav√©s de un bloque residual en lugar de obtenerse de una tabla de b√∫squeda (como en los modelos de lenguaje tradicionales, por ejemplo), ya que los datos son continuos. El modelo se entrena para minimizar la el error cuadr√°tico medio (MSE, por sus siglas en ingl√©s) entre cada token y otro, obtenido en un horizonte \\(h\\) en el futuro.\nLa figura anterior ilustra la arquitectura del modelo TimesFM durante el entrenamiento, en el que una serie temporal de una longitud espec√≠fica se descompone en una serie de parches. Como ya se mencion√≥, cada parche es procesado por un bloque residual que lo mapea a la dimensi√≥n necesaria para pasar por las capas del transformer. El modelo usa codificaciones posicionales sinusoidales (bien tradicionales, similares a las que se usan en el paper original presentando el transformer como arquitectura). La longitud de los parches y el horizonte \\(h\\) var√≠an durante el entrenamiento, para evitar que el modelo se ajuste en exceso a una √∫nica configuraci√≥n r√≠gida.\nEl paper incluye una serie de experimentos que exploran diferentes configuraciones y esquemas de parcheo en diferentes benchmarks, alcanzando en muchos de ellos rendimiento SOTA en tareas de zero-shot. Aunque se trata sin duda de un art√≠culo a tener en cuenta, una de sus principales limitaciones es que se centra √∫nicamente en series temporales univariandas. A pesar de que el entrenamiento de modelos de representaci√≥n en series temporales multivariadas es un problema mucho m√°s dif√≠cil, hay varios trabajos recientes que ya estudian esta cuesti√≥n. Por ejemplo, iTransformer invierte la estrategia de codificaci√≥n al tokenizar cada variable de forma independiente en toda la dimensi√≥n temporal, con un mecanismo de atenci√≥n que se centra en las interacciones entre variables. Otro esfuerzo interesante, que alcanza rendimiento SOTA en muchas pruebas comparativas y aprovecha datos de m√∫ltiples fuentes, es UniTS. Este modelo tiene mecanismos de atenci√≥n separados que funcionan tanto a entre variables como a trav√©s del tiempo, e incluye diferentes conjuntos de tokens para especificar una de varias tareas, incluyendo forecasting, imputaci√≥n y detecci√≥n de anomal√≠as.\n2Bits de prote√≠na: modelos de lenguaje proteicos eficientes a escala de 2 bits Por √∫ltimo, cambiamos un poco de tema y pasamos a los modelos de lenguaje de prote√≠nas. 2Bits of protein es un art√≠culo que se present√≥ durante los talleres del √∫ltimo d√≠a de la conferencia, que se basa en la idea reciente de entrenar modelos de lenguaje con par√°metros ternarios, que pueden establecerse en cero, uno o menos uno. Se trata de un tema realmente relevante en el momento de escribir, habi√©ndose demostrado ampliamente que este tipo de modelos conservan la mayor parte de la precisi√≥n de sus hom√≥logos de precisi√≥n completa, al tiempo que son mucho m√°s eficientes en t√©rminos de memoria y costo computacional. Esto tiene implicaciones enormes para peque√±as y medianas empresas, as√≠ como para laboratorios de investigaci√≥n que no tienen acceso a los mismos recursos computacionales que las grandes empresas del sector. Adem√°s, la capacidad de entrenar y ejecutar modelos localmente promete ventajas en t√©rminos de privacidad y seguridad de los datos, lo que es importante en cualquier aplicaci√≥n relacionada con la salud (entre muchas otras, desde ya).\nEn este trabajo, los autores investigan el entrenamiento de un pLM s√≥lo codificador utilizando una arquitectura ternaria, y lo comparan con ESM2 (con precisi√≥n est√°ndar) en varias tareas de ProteinGym. Aunque el modelo ternario no es tan bueno como el de precisi√≥n est√°ndar, sigue siendo competitivo en muchas tareas y es mucho m√°s eficiente. Los autores tambi√©n afirman que, bas√°ndose en el trabajo fundacional en este campo que menciono m√°s arriba, cabe esperar que las variantes ternarias superen a ESM-2 una vez que se aumente el tama√±o del modelo. ¬°Esto est√° por verse!\nAc√° un fragmento de los resultados (con leyendas autoexplicativas):\nEn definitiva, creo que el impacto de estos enfoques puede ser enorme tanto para los peque√±os como para los grandes actores. Por un lado, permite a gente sin hardware SOTA entrenar y utilizar mejores modelos, pero tambi√©n permite a las grandes empresas entrenar modelos mucho m√°s grandes de lo que podr√≠an hacerlo de otro modo. Veremos si estas pr√°cticas se generalizan en los pr√≥ximos a√±os.\n",
  "wordCount" : "1372",
  "inLanguage": "es",
  "image":"//localhost:1313/ICML_logo.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Lucas Miranda"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "//localhost:1313/es/blog/icml24/icml24/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Lucas Miranda",
    "logo": {
      "@type": "ImageObject",
      "url": "//localhost:1313/assets/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="//localhost:1313/es/" accesskey="h" title="Lucas Miranda (Alt + H)">Lucas Miranda</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="//localhost:1313/en/" title="üá¨üáß"
                            aria-label="English">En</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="//localhost:1313/es/about/" title="Bio">
                    <span>Bio</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/es/pubs/" title="Publicaciones">
                    <span>Publicaciones</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/es/software/" title="Software">
                    <span>Software</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/es/blog/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/es/search/" title="B√∫squeda">
                    <span>B√∫squeda</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      International Conference on Machine Learning 2024
    </h1>
    <div class="post-meta">7 min&nbsp;¬∑&nbsp;Lucas Miranda&nbsp;|&nbsp;Traducciones:
<ul class="i18n_list">
    <li>
        <a href="//localhost:1313/en/blog/icml24/icml24/">En</a>
    </li>
</ul>

</div>
  </header> 
<figure class="entry-cover"><img loading="eager" src="//localhost:1313/ICML_logo.png" alt="ICML24 logo">
        
</figure>
  <div class="post-content"><h3 id="impresiones-generales">Impresiones generales<a hidden class="anchor" aria-hidden="true" href="#impresiones-generales">#</a></h3>
<p>Esta vez escribo desde Viena, Austria, ciudad que visit√© con motivo de la Conferencia Internacional sobre Aprendizaje Autom√°tico (ICML). Organic√© mi agenda mucho mejor que <a href="https://lucasmiranda42.github.io/digital_home/es/blog/neurips23/neurips23/">la √∫ltima vez</a>, y obtuve mucha informaci√≥n sobre los nuevos avances en varias √°reas que me interesan, como la representaci√≥n de series temporales, la inform√°tica m√©dica y la biolog√≠a computacional de prote√≠nas. Abajo mi humilde selecci√≥n de art√≠culos favoritos. Espero que encuentres algo interesante.</p>
<h3 id="aprendizaje-por-contraste-para-la-predicci√≥n-de-resultados-cl√≠nicos-con-fuentes-de-datos-parciales">Aprendizaje por contraste para la predicci√≥n de resultados cl√≠nicos con fuentes de datos parciales<a hidden class="anchor" aria-hidden="true" href="#aprendizaje-por-contraste-para-la-predicci√≥n-de-resultados-cl√≠nicos-con-fuentes-de-datos-parciales">#</a></h3>
<p>Empezamos con una <a href="https://openreview.net/pdf?id=elCOPIm4Xw">contribuci√≥n significativa</a> al campo de la inform√°tica m√©dica. A medida que las historias cl√≠nicas electr√≥nicas(EHR, por sus siglas en ingl√©s) se hacen m√°s y m√°s comunes en todo el mundo, vemos que los nuevos m√©todos para procesarlas, representarlas y predecir a partir de ellas cobran cada vez m√°s importancia. En este caso, los autores presentan <strong>CLOPPS</strong> (Contrastive Learning for clinical Outcome Prediction with Partial data Sources), cuyo objetivo es capturar informaci√≥n de distintas fuentes de datos de los mismos pacientes y alinearlas durante el entrenamiento mediante aprendizaje por contraste. Es importante destacar que lo hacen de manera que no todas las modalidades son necesarias en el momento de la inferencia, lo que constituye una limitaci√≥n com√∫n en muchos modelos en este campo.</p>
<p><img loading="lazy" src="../../../../contrastive_med_align.png" alt="Contrastive Learning for Clinical Outcome Prediction with Partial Data Sources"  title="Contrastive Learning for Clinical Outcome Prediction with Partial Data Sources"  />
</p>
<p>La figura de arriba representa el flujo de trabajo de preentrenamiento que los autores usan en CLOPPS: dadas dos observaciones longitudinales, el descodificador de la izquierda produce representaciones para cada modalidad, que luego se alinean contrastivamente en el espacio latente. La funci√≥n de coste total es la suma de dos t√©rminos InfoNCE, que siguen estrategias separadas de muestreo de pares positivos/negativos, y un t√©rmino de predicci√≥n a futuro (<em>forecasting</em>). El primero, \(L_M\), busca imponer coincidencia temporal entre modalidades. Ac√°, la asunci√≥n es que las distintas fuentes representan de forma colectiva y complementaria el estado de salud en ese momento, por lo que muestras tomadas al mismo tiempo en diversas fuentes son las √∫nicas consideradas como pares positivos. En segundo lugar, el modelo incorpora un t√©rmino de similitud local bastante original (\(L_L\)), basado en un estimador de Kaplan-Meier (KM) para el fen√≥meno que se est√© intentando predecir. La idea es simple: si el paciente est√° sano, las series temporales no cambian tanto en un periodo de tiempo corto, y la amplitud del vecindario local del que muestrear pares positivos puede ser mayor. Si el paciente est√° enfermo, la curva de KM es m√°s pronunciada y el vecindario del que tomar muestras de pares positivos es m√°s chico. Mientras que \(L_M\) se encarga de alinear estrictamente las fuentes de datos a lo largo del tiempo, \(L_L\) se centra en las regiones de cambio r√°pido, que se corresponden con peores resultados seg√∫n lo predicho por el estimador KM. Como idea me suena b√°rbara, y los estudios de ablaci√≥n incluidos en el art√≠culo muestran que es relevante. Por √∫ltimo, el tercer t√©rmino, \(L_F\), es una p√©rdida de <em>forecasting</em> entrenada por modalidad de forma independiente.</p>
<hr>
<p>Para una revisi√≥n de la funci√≥n de coste InfoNCE est√°ndar, ¬°pasate por <a href="https://lucasmiranda42.github.io/digital_home/es/blog/neurips23/neurips23/">este</a> post!</p>
<hr>
<p>En cuanto a los experimentos, los autores muestran rendimiento SOTA en una serie de escenarios, motivados por un problema del mundo real en el que los datos proceden tanto de un proveedor de di√°lisis como de un sistema de datos nacional estadounidense -el United States Renal Data System (USRDS)-. En este caso, como los datos del flujo nacional no siempre est√°n disponibles, es crucial desarrollar un modelo que pueda hacer predicciones cuando falten algunos datos.</p>
<h3 id="timesfm-un-modelo-fundacional-decoder-only-para-forecasting-de-series-temporales">TimesFM: un modelo fundacional decoder-only para forecasting de series temporales<a hidden class="anchor" aria-hidden="true" href="#timesfm-un-modelo-fundacional-decoder-only-para-forecasting-de-series-temporales">#</a></h3>
<p>Este es un art√≠culo que, como muchos otros procedentes de Google, estuvo por todo Internet cuando sali√≥. Ten√≠a muchas ganas de ver el p√≥ster, y me alegro de haber podido pasarme y charlar con los autores. Como indica el t√≠tulo, <a href="https://arxiv.org/pdf/2310.10688">TimesFM</a> es un modelo basado √∫nicamente en decodificadores para el forecasting de series temporales univariadas, entrenado tanto en tendencias de Google como en estad√≠sticas de acceso a wikimedia.</p>
<p>Los datos est√°n tokenizados a lo largo del tiempo, y la arquitectura se corresponde con un transformer s√≥lo decodificador est√°ndar, en el que los &rsquo;tokens&rsquo; pasan a trav√©s de un bloque residual en lugar de obtenerse de una tabla de b√∫squeda (como en los modelos de lenguaje tradicionales, por ejemplo), ya que los datos son continuos. El modelo se entrena para minimizar la el error cuadr√°tico medio (MSE, por sus siglas en ingl√©s) entre cada token y otro, obtenido en un horizonte \(h\) en el futuro.</p>
<p><img loading="lazy" src="../../../../timesfm.png" alt="TimesFM"  title="TimesFM"  />
</p>
<p>La figura anterior ilustra la arquitectura del modelo TimesFM durante el entrenamiento, en el que una serie temporal de una longitud espec√≠fica se descompone en una serie de parches. Como ya se mencion√≥, cada parche es procesado por un bloque residual que lo mapea a la dimensi√≥n necesaria para pasar por las capas del transformer. El modelo usa codificaciones posicionales sinusoidales (bien tradicionales, similares a las que se usan en el <a href="https://arxiv.org/abs/1706.03762">paper original</a> presentando el transformer como arquitectura). La longitud de los parches y el horizonte \(h\) var√≠an durante el entrenamiento, para evitar que el modelo se ajuste en exceso a una √∫nica configuraci√≥n r√≠gida.</p>
<p>El paper incluye una serie de experimentos que exploran diferentes configuraciones y esquemas de parcheo en diferentes benchmarks, alcanzando en muchos de ellos rendimiento SOTA en tareas de zero-shot. Aunque se trata sin duda de un art√≠culo a tener en cuenta, una de sus principales limitaciones es que se centra √∫nicamente en series temporales univariandas. A pesar de que el entrenamiento de modelos de representaci√≥n en series temporales multivariadas es un problema mucho m√°s dif√≠cil, hay varios trabajos recientes que ya estudian esta cuesti√≥n. Por ejemplo, <a href="https://arxiv.org/abs/2310.06625">iTransformer</a> invierte la estrategia de codificaci√≥n al tokenizar cada variable de forma independiente en toda la dimensi√≥n temporal, con un mecanismo de atenci√≥n que se centra en las interacciones entre variables. Otro esfuerzo interesante, que alcanza rendimiento SOTA en muchas pruebas comparativas y aprovecha datos de m√∫ltiples fuentes, es <a href="https://arxiv.org/abs/2403.00131">UniTS</a>. Este modelo tiene mecanismos de atenci√≥n separados que funcionan tanto a entre variables como a trav√©s del tiempo, e incluye diferentes conjuntos de tokens para especificar una de varias tareas, incluyendo <em>forecasting</em>, imputaci√≥n y detecci√≥n de anomal√≠as.</p>
<h3 id="2bits-de-prote√≠na-modelos-de-lenguaje-proteicos-eficientes-a-escala-de-2-bits">2Bits de prote√≠na: modelos de lenguaje proteicos eficientes a escala de 2 bits<a hidden class="anchor" aria-hidden="true" href="#2bits-de-prote√≠na-modelos-de-lenguaje-proteicos-eficientes-a-escala-de-2-bits">#</a></h3>
<p>Por √∫ltimo, cambiamos un poco de tema y pasamos a los modelos de lenguaje de prote√≠nas. <a href="https://openreview.net/pdf?id=bVQjzz3ABw">2Bits of protein</a> es un art√≠culo que se present√≥ durante los talleres del √∫ltimo d√≠a de la conferencia, que se basa en la <a href="https://arxiv.org/pdf/2402.17764">idea reciente</a> de entrenar modelos de lenguaje con par√°metros ternarios, que pueden establecerse en cero, uno o menos uno. Se trata de un tema realmente relevante en el momento de escribir, habi√©ndose demostrado ampliamente que este tipo de modelos conservan la mayor parte de la precisi√≥n de sus hom√≥logos de precisi√≥n completa, al tiempo que son mucho m√°s eficientes en t√©rminos de memoria y costo computacional. Esto tiene implicaciones enormes para peque√±as y medianas empresas, as√≠ como para laboratorios de investigaci√≥n que no tienen acceso a los mismos recursos computacionales que las grandes empresas del sector. Adem√°s, la capacidad de entrenar y ejecutar modelos localmente promete ventajas en t√©rminos de privacidad y seguridad de los datos, lo que es importante en cualquier aplicaci√≥n relacionada con la salud (entre muchas otras, desde ya).</p>
<p>En este trabajo, los autores investigan el entrenamiento de un pLM s√≥lo codificador utilizando una arquitectura ternaria, y lo comparan con ESM2 (con precisi√≥n est√°ndar) en varias tareas de ProteinGym. Aunque el modelo ternario no es tan bueno como el de precisi√≥n est√°ndar, sigue siendo competitivo en muchas tareas y es mucho m√°s eficiente. Los autores tambi√©n afirman que, bas√°ndose en el trabajo fundacional en este campo que menciono m√°s arriba, cabe esperar que las variantes ternarias superen a ESM-2 una vez que se aumente el tama√±o del modelo. ¬°Esto est√° por verse!</p>
<p>Ac√° un fragmento de los resultados (con leyendas autoexplicativas):</p>
<p><img loading="lazy" src="../../../../2bitplm.png" alt="2Bits of Protein"  title="2Bits of Protein"  />
</p>
<p>En definitiva, creo que el impacto de estos enfoques puede ser enorme tanto para los peque√±os como para los grandes actores. Por un lado, permite a gente sin hardware SOTA entrenar y utilizar mejores modelos, pero tambi√©n permite a las grandes empresas entrenar modelos mucho m√°s grandes de lo que podr√≠an hacerlo de otro modo. Veremos si estas pr√°cticas se generalizan en los pr√≥ximos a√±os.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="//localhost:1313/es/tags/conferencias/">Conferencias</a></li>
      <li><a href="//localhost:1313/es/tags/aprendizaje-autom%C3%A1tico/">Aprendizaje Autom√°tico</a></li>
      <li><a href="//localhost:1313/es/tags/aprendizaje-profundo/">Aprendizaje Profundo</a></li>
      <li><a href="//localhost:1313/es/tags/viajes/">Viajes</a></li>
      <li><a href="//localhost:1313/es/tags/icml/">ICML</a></li>
      <li><a href="//localhost:1313/es/tags/austria/">Austria</a></li>
      <li><a href="//localhost:1313/es/tags/viena/">Viena</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="//localhost:1313/es/">Lucas Miranda</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/shinying/hugo-PaperMod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
