
<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>DeepOF | Lucas Miranda</title>
<meta name="keywords" content="Software, DeepOF, DeepLabCut, SLEAP, Rodents, Time-series, Postprocessing, Videos, Python, Jupyter, Machine Learning, Deep Learning, Behavior">
<meta name="description" content="A suite for postprocessing time-series extracted from videos of freely moving rodents using DeepLabCut and SLEAP.">
<meta name="author" content="Lucas Miranda">
<link rel="canonical" href="//localhost:1313/en/software/deepof/deepof/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.1f0c81ce7797be919c6536baf557152f60cccb49e7a37ce74f7fd3fd705259f6.css" integrity="sha256-HwyBzneXvpGcZTa69VcVL2DMy0nno3znT3/T/XBSWfY=" rel="preload stylesheet" as="style">
<link rel="icon" href="//localhost:1313/assets/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="//localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="//localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="//localhost:1313/en/software/deepof/deepof/">
<link rel="alternate" hreflang="es" href="//localhost:1313/es/software/deepof/deepof/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="DeepOF" />
<meta property="og:description" content="A suite for postprocessing time-series extracted from videos of freely moving rodents using DeepLabCut and SLEAP." />
<meta property="og:type" content="article" />
<meta property="og:url" content="//localhost:1313/en/software/deepof/deepof/" />
<meta property="og:image" content="//localhost:1313/deepof_cover.png" /><meta property="article:section" content="software" />





<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="//localhost:1313/deepof_cover.png" />
<meta name="twitter:title" content="DeepOF"/>
<meta name="twitter:description" content="A suite for postprocessing time-series extracted from videos of freely moving rodents using DeepLabCut and SLEAP."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Software",
      "item": "//localhost:1313/en/software/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "DeepOF",
      "item": "//localhost:1313/en/software/deepof/deepof/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "DeepOF",
  "name": "DeepOF",
  "description": "A suite for postprocessing time-series extracted from videos of freely moving rodents using DeepLabCut and SLEAP.",
  "keywords": [
    "Software", "DeepOF", "DeepLabCut", "SLEAP", "Rodents", "Time-series", "Postprocessing", "Videos", "Python", "Jupyter", "Machine Learning", "Deep Learning", "Behavior"
  ],
  "articleBody": "DeepOF is a Python suite to process animal motion tracking data, obtained using DeepLabCut or SLEAP. The tools we have when it comes to quantifying what animals do have evolved significantly in the last decade. Starting from observational research of animals in the wild, the field of ethology massively shifted towards more simplistic and controlled tests in the lab, often measuring relatively simplistic univariate responses to stimuli.\nRecently, advances is computer vision and machine learning allowed researchers to thoroughly track the detailed movement of animals both in the lab and in the wild, without the need for physical labels! Typically, these programs rely on transfer learning from neural networks pretrained on large image datasets, which first extract video frame features. Upon labelling relatively few frames with body parts of interest, the networks can then be fine-tuned to track these body parts across the entire video dataset we have. Below you can see the general workflow of the original DeepLabCut paper. More modern architectures can track keypoints even with no labelling at all, although they remain less accurate than these supervised fine-tuned methods.\nBy transforming raw video footage into time series of tracked body parts, these approaches (including the aforementioned DeepLabCut and SLEAP) paved the way for analysis tools that can automatically tag and characterize behavior in many innovative ways.\nDeepOF is our humble contribution to this endeavor. It offers both supervised and unsupervised annotation pipelines, that allow researchers to test hypotheses regarding experimental conditions such as stress, gene mutations, and sex, in a flexible way.\nThe included supervised pipeline uses a series of rule-based annotators and pre-trained machine learning models to detect when the animals that are being tracked are displaying any of a set of pre-defined behavioral patterns.\nThis way, we can tag both individual and social behaviors with just a few commands! Letâ€™s see a basic example:\nimport deepof.data my_deepof_project_raw = deepof.data.Project( project_path=os.path.join(\"tutorial_files\"), video_path=os.path.join(\"tutorial_files/Videos/\"), table_path=os.path.join(\"tutorial_files/Tables/\"), project_name=\"deepof_example_project\", ) supervised_annotation = my_deepof_project.supervised_annotation() And thatâ€™s it! You have now annotated your videos with a set of pre-trained models that can detect behaviors such as huddling, climbing, and social interactions.\nMoreover, DeepOF also provides an unsupervised workflow, that uses deep clustering models to uncover behavioral patterns without prior definition, which can also be run with a few lines of code:\n# Continuing from before, we create a set of coordinates to cluster, # removing unwanted positional and rotational variation coords = my_deepof_project.get_coords(center=\"Center\", align=\"Spine_1\") # We then preprocess these coordinates to make them suitable for clustering preprocessed_coords, global_scaler = coords.preprocess() # Finally, we cluster these preprocessed coordinates using a deep clustering model trained_model = my_deepof_project.deep_unsupervised_embedding( preprocessed_object=preprocessed_coords ) We then also include an interpretability pipeline to explore what these retrieved clusters are, relying on both Shapley Additive Explanations (SHAP) and direct mappings from clusters to video snippets. Moreover, regardless of the type of analysis you chose, DeepOF has you covered with an extensive set of post-hoc analysis and visualization tools. Below you can see the SHAP results, as well as video snippets, for a huddling cluster enriched in animals that were exposed to chronic stress.\nThatâ€™s all for now. All in all, DeepOF is a versatile tool that can help you extract meaningful information from your animal behavior data, and we hope you find it as useful as we do!\nWhere do I go next? DeepOF is available on GitHub and PyPI. You can detailed installation instructions, as well as documentation and tutorials here. Moreover, there are two publications you can read! One about the software itself, and another one in which we used to characterize a mouse model of chronic stress!\n",
  "wordCount" : "598",
  "inLanguage": "en",
  "image":"//localhost:1313/deepof_cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Lucas Miranda"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "//localhost:1313/en/software/deepof/deepof/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Lucas Miranda",
    "logo": {
      "@type": "ImageObject",
      "url": "//localhost:1313/assets/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="//localhost:1313/en/" accesskey="h" title="Lucas Miranda (Alt + H)">Lucas Miranda</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="//localhost:1313/es/" title="ðŸ§‰"
                            aria-label="EspaÃ±ol">Es</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="//localhost:1313/en/about/" title="Bio">
                    <span>Bio</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/en/pubs/" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/en/software/" title="Software">
                    <span>Software</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/en/blog/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/en/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      DeepOF
    </h1>
    <div class="post-meta">3 min&nbsp;Â·&nbsp;Lucas Miranda&nbsp;|&nbsp;Translations:
<ul class="i18n_list">
    <li>
        <a href="//localhost:1313/es/software/deepof/deepof/">Es</a>
    </li>
</ul>

</div>
  </header> 
<figure class="entry-cover"><img loading="eager" src="//localhost:1313/deepof_cover.png" alt="DeepOF logo with text">
        
</figure>
  <div class="post-content"><h3 id="deepof-is-a-python-suite-to-process-animal-motion-tracking-data-obtained-using-deeplabcut-or-sleap">DeepOF is a Python suite to process animal motion tracking data, obtained using <a href="https://www.mackenziemathislab.org/deeplabcut#:~:text=DeepLabCut%E2%84%A2%20is%20an%20efficient,typically%2050%2D200%20frames">DeepLabCut</a> or <a href="https://sleap.ai/">SLEAP</a>.<a hidden class="anchor" aria-hidden="true" href="#deepof-is-a-python-suite-to-process-animal-motion-tracking-data-obtained-using-deeplabcut-or-sleap">#</a></h3>
<p>The tools we have when it comes to quantifying what animals do have evolved significantly in
the last decade. Starting from observational research of animals in the wild, the field of ethology massively shifted towards more simplistic and controlled tests in the lab, often measuring relatively simplistic univariate responses to stimuli.</p>
<p>Recently, advances is computer vision and machine learning allowed researchers to thoroughly track the detailed movement of animals both in the lab and in the wild, without the need for physical labels! Typically, these programs rely on transfer learning from neural networks pretrained on large image datasets, which first extract video frame features. Upon labelling relatively few frames with body parts of interest, the networks can then be fine-tuned to track these body parts across the entire video dataset we have. Below you can see the general workflow of the <a href="https://www.nature.com/articles/s41593-018-0209-y">original DeepLabCut paper</a>. More modern architectures can track keypoints <a href="https://arxiv.org/abs/2203.07436">even with no labelling at all</a>, although they remain less accurate than these supervised fine-tuned methods.</p>
<p><img loading="lazy" src="../deeplabcut.png" alt="Supervised pipeline in DeepOF"  />
</p>
<p>By transforming raw video footage into time series of tracked body parts, these approaches (including the aforementioned <a href="https://www.mackenziemathislab.org/deeplabcut#:~:text=DeepLabCut%E2%84%A2%20is%20an%20efficient,typically%2050%2D200%20frames">DeepLabCut</a> and <a href="https://sleap.ai/">SLEAP</a>) paved the way for analysis tools that can automatically tag and characterize behavior in many innovative ways.</p>
<p>DeepOF is our humble contribution to this endeavor. It offers both supervised and unsupervised annotation pipelines, that allow researchers to test hypotheses regarding experimental conditions such as stress, gene mutations, and sex, in a flexible way.</p>
<p>The included supervised pipeline uses a series of rule-based annotators and pre-trained machine learning models to detect when the animals that are being tracked are displaying any of a set of pre-defined behavioral patterns.</p>
<p><img loading="lazy" src="../deepof_supervised.png" alt="Supervised pipeline in DeepOF"  />
</p>
<p>This way, we can tag both individual and social behaviors with just a few commands! Let&rsquo;s see a basic example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> deepof.data
</span></span><span style="display:flex;"><span>my_deepof_project_raw <span style="color:#f92672">=</span> deepof<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Project(
</span></span><span style="display:flex;"><span>                project_path<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(<span style="color:#e6db74">&#34;tutorial_files&#34;</span>),
</span></span><span style="display:flex;"><span>                video_path<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(<span style="color:#e6db74">&#34;tutorial_files/Videos/&#34;</span>),
</span></span><span style="display:flex;"><span>                table_path<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(<span style="color:#e6db74">&#34;tutorial_files/Tables/&#34;</span>),
</span></span><span style="display:flex;"><span>                project_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;deepof_example_project&#34;</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>supervised_annotation <span style="color:#f92672">=</span> my_deepof_project<span style="color:#f92672">.</span>supervised_annotation()
</span></span></code></pre></div><p>And that&rsquo;s it! You have now annotated your videos with a set of pre-trained models that can detect behaviors such as huddling, climbing, and social interactions.</p>
<p>Moreover, DeepOF also provides an unsupervised workflow, that uses deep clustering models to uncover behavioral patterns without prior definition, which can also be run with a few lines of code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Continuing from before, we create a set of coordinates to cluster, </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># removing unwanted positional and rotational variation</span>
</span></span><span style="display:flex;"><span>coords <span style="color:#f92672">=</span> my_deepof_project<span style="color:#f92672">.</span>get_coords(center<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Center&#34;</span>, align<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Spine_1&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># We then preprocess these coordinates to make them suitable for clustering</span>
</span></span><span style="display:flex;"><span>preprocessed_coords, global_scaler <span style="color:#f92672">=</span> coords<span style="color:#f92672">.</span>preprocess()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Finally, we cluster these preprocessed coordinates using a deep clustering model</span>
</span></span><span style="display:flex;"><span>trained_model <span style="color:#f92672">=</span> my_deepof_project<span style="color:#f92672">.</span>deep_unsupervised_embedding(
</span></span><span style="display:flex;"><span>  preprocessed_object<span style="color:#f92672">=</span>preprocessed_coords
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>We then also include an interpretability pipeline to explore what these retrieved clusters are, relying on both Shapley Additive Explanations (SHAP) and direct mappings from clusters to video snippets. Moreover, regardless of the type of analysis you chose, DeepOF has you covered with an extensive set of post-hoc analysis and
visualization tools. Below you can see the SHAP results, as well as video snippets, for a huddling cluster enriched in animals that were exposed to chronic stress.</p>
<p><img loading="lazy" src="../deepof_unsupervised.gif" alt="Unsupervised pipeline in DeepOF"  />
</p>
<p>That&rsquo;s all for now. All in all, DeepOF is a versatile tool that can help you extract meaningful information from your animal behavior data, and we hope you find it as useful as we do!</p>
<h3 id="where-do-i-go-next">Where do I go next?<a hidden class="anchor" aria-hidden="true" href="#where-do-i-go-next">#</a></h3>
<p>DeepOF is available on <a href="https://github.com/mlfpm/deepof">GitHub</a> and <a href="https://pypi.org/project/deepof/">PyPI</a>. You can detailed installation instructions, as well as documentation and tutorials <a href="https://deepof.readthedocs.io/en/latest/">here</a>. Moreover, there are two publications you can read! One about the <a href="https://joss.theoj.org/papers/10.21105/joss.05394">software itself</a>, and another one in which we used to <a href="https://www.nature.com/articles/s41467-023-40040-3">characterize a mouse model of chronic stress</a>!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="//localhost:1313/en/tags/software/">Software</a></li>
      <li><a href="//localhost:1313/en/tags/deepof/">DeepOF</a></li>
      <li><a href="//localhost:1313/en/tags/deeplabcut/">DeepLabCut</a></li>
      <li><a href="//localhost:1313/en/tags/sleap/">SLEAP</a></li>
      <li><a href="//localhost:1313/en/tags/rodents/">Rodents</a></li>
      <li><a href="//localhost:1313/en/tags/time-series/">Time-Series</a></li>
      <li><a href="//localhost:1313/en/tags/postprocessing/">Postprocessing</a></li>
      <li><a href="//localhost:1313/en/tags/videos/">Videos</a></li>
      <li><a href="//localhost:1313/en/tags/python/">Python</a></li>
      <li><a href="//localhost:1313/en/tags/jupyter/">Jupyter</a></li>
      <li><a href="//localhost:1313/en/tags/machine-learning/">Machine Learning</a></li>
      <li><a href="//localhost:1313/en/tags/deep-learning/">Deep Learning</a></li>
      <li><a href="//localhost:1313/en/tags/behavior/">Behavior</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="//localhost:1313/en/">Lucas Miranda</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/shinying/hugo-PaperMod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
